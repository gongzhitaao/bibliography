#+TITLE: Notes on: Sch\"{o}lkopf, Bernhard (2019): Causality for machine learning

* Gist

the phenomenon of "adversarial vulnerability" highlights how even tiny but
targeted violations of the IID assumption, generated by adding suitably chosen
noise to images (imperceptible to humans), can lead to dangerous errors such as
confusion of traffic signs.

I like to think of a set of coupled /differential equations/ as the gold standard
in modeling physical phenomena.

We /always/ need assumptions when we perform nontrivial inference from data

The Kolmogorov complexity (or algorithmic information) of a bit string is
essentially the length of its shortest compression on a Turing machine, and thus
a measure of its information content.

It introduced a measure of dependence between the input and the conditional of
output given input, and showed that if this dependence is zero in the causal
direction, then it would be strictly positive in the opposite direction

* Questions

- I could see it is useful, how to learn causality from the data?
